package executors

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io/ioutil"
	"math/rand"
	"net/http"
	"time"

	"github.com/dblogscomparator/DBLogsComparator/load_tool/go_querier/pkg/models"
)

// ElasticsearchExecutor query executor for Elasticsearch
type ElasticsearchExecutor struct {
	BaseURL   string
	Client    *http.Client
	Options   models.Options
	IndexName string
}

// ESSearchResponse represents the response from Elasticsearch
type ESSearchResponse struct {
	Took     int  `json:"took"`
	TimedOut bool `json:"timed_out"`
	Hits     struct {
		Total struct {
			Value    int    `json:"value"`
			Relation string `json:"relation"`
		} `json:"total"`
		MaxScore float64       `json:"max_score"`
		Hits     []interface{} `json:"hits"`
	} `json:"hits"`
	Aggregations map[string]interface{} `json:"aggregations,omitempty"`
}

// ESErrorResponse represents an error from Elasticsearch
type ESErrorResponse struct {
	Error struct {
		Type   string `json:"type"`
		Reason string `json:"reason"`
	} `json:"error"`
	Status int `json:"status"`
}

// Constants for ES query generation
var (
	// Log types matching those generated by the log generator
	esLogTypes = []string{
		"web_access", "web_error", "application", "metric", "event",
	}

	// Field names from log structure for queries
	esFields = []string{
		"log_type", "host", "container_name", "environment", "datacenter", "timestamp",
		"level", "message", "remote_addr", "request", "status", "bytes_sent",
		"http_referer", "http_user_agent", "request_time", "error_code", "service",
		"exception", "stacktrace", "request_id", "request_path", "client_ip",
		"trace_id", "span_id", "request_method", "response_status", "response_time",
		"metric_name", "value", "region", "event_type", "resource_id", "namespace",
	}

	// Common phrases for keyword search in message field
	esQueryPhrases = []string{
		"error", "warning", "exception", "failed", "timeout", "success",
		"completed", "running", "critical", "forbidden", "GET", "POST", "PUT", "DELETE",
	}
)

// NewElasticsearchExecutor creates a new query executor for Elasticsearch
func NewElasticsearchExecutor(baseURL string, options models.Options) *ElasticsearchExecutor {
	client := &http.Client{
		Timeout: options.Timeout,
	}

	return &ElasticsearchExecutor{
		BaseURL:   baseURL,
		Client:    client,
		Options:   options,
		IndexName: "logs-*", // Using a mask for all log indices
	}
}

// GetSystemName returns the system name
func (e *ElasticsearchExecutor) GetSystemName() string {
	return "elasticsearch"
}

// ExecuteQuery executes a query of the specified type in Elasticsearch
func (e *ElasticsearchExecutor) ExecuteQuery(ctx context.Context, queryType models.QueryType) (models.QueryResult, error) {
	// Create a random query of the specified type
	query := e.GenerateRandomQuery(queryType).(map[string]interface{})

	// Execute the query to Elasticsearch
	result, err := e.executeElasticsearchQuery(ctx, query)
	if err != nil {
		return models.QueryResult{}, err
	}

	return result, nil
}

// GenerateRandomQuery generates a random Elasticsearch query based on the query type
func (e *ElasticsearchExecutor) GenerateRandomQuery(queryType models.QueryType) interface{} {
	// Shorter time range - last hour instead of 7 days
	now := time.Now()
	startTime := now.Add(-24 * time.Hour)

	// Format times for Elasticsearch (ISO format)
	startTimeStr := startTime.Format(time.RFC3339)
	endTimeStr := now.Format(time.RFC3339)

	// Create base query structure with time range filter
	baseQuery := map[string]interface{}{
		"size": 100,
		"query": map[string]interface{}{
			"bool": map[string]interface{}{
				"filter": []interface{}{
					map[string]interface{}{
						"range": map[string]interface{}{
							"timestamp": map[string]interface{}{
								"gte": startTimeStr,
								"lte": endTimeStr,
							},
						},
					},
				},
			},
		},
	}

	// Reference to the bool query's filters for easier access
	filters := baseQuery["query"].(map[string]interface{})["bool"].(map[string]interface{})["filter"].([]interface{})

	// Depending on query type, add different filters and structure
	switch queryType {
	case models.SimpleQuery:
		// Simple query type - select from different simple scenarios
		querySubtype := rand.Intn(5)

		switch querySubtype {
		case 0:
			// Filter by log_type only
			logType := esLogTypes[rand.Intn(len(esLogTypes))]
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"log_type": logType,
				},
			})

		case 1:
			// Search by keyword in message field
			keyword := esQueryPhrases[rand.Intn(len(esQueryPhrases))]

			// Add a match for the message field
			filters = append(filters, map[string]interface{}{
				"match": map[string]interface{}{
					"message": keyword,
				},
			})

		case 2:
			// Filter by log level
			levels := []string{"debug", "info", "warn", "error", "critical"}
			level := levels[rand.Intn(len(levels))]

			// Add log type filter for application or web_error (where level makes sense)
			logType := []string{"web_error", "application"}[rand.Intn(2)]
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"log_type": logType,
				},
			})

			// Add level filter
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"level": level,
				},
			})

		case 3:
			// Filter web_access logs by status code
			statuses := []int{200, 201, 204, 301, 302, 400, 401, 403, 404, 500, 502, 503}
			status := statuses[rand.Intn(len(statuses))]

			// Add log type filter for web_access
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"log_type": "web_access",
				},
			})

			// Add status filter
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"status": status,
				},
			})

		default:
			// Filter by container name (most likely to find logs)
			containers := []string{"app", "web", "api", "db", "cache", "auth"}
			container := containers[rand.Intn(len(containers))]
			filters = append(filters, map[string]interface{}{
				"wildcard": map[string]interface{}{
					"container_name": "*" + container + "*",
				},
			})
		}

	case models.ComplexQuery:
		// Complex query with multiple filters based on log type
		logType := esLogTypes[rand.Intn(len(esLogTypes))]

		// Add base log type filter
		filters = append(filters, map[string]interface{}{
			"term": map[string]interface{}{
				"log_type": logType,
			},
		})

		// Add type-specific conditions
		switch logType {
		case "web_access":
			// For web access logs, add filters based on HTTP status and methods
			if rand.Intn(2) == 0 {
				// Status range filter (2xx, 4xx, or 5xx)
				statuses := []int{200, 400, 500}
				baseStatus := statuses[rand.Intn(len(statuses))]
				filters = append(filters, map[string]interface{}{
					"range": map[string]interface{}{
						"status": map[string]interface{}{
							"gte": baseStatus,
							"lt":  baseStatus + 100,
						},
					},
				})
			} else {
				// HTTP method filter
				methods := []string{"GET", "POST", "PUT", "DELETE"}
				method := methods[rand.Intn(len(methods))]
				filters = append(filters, map[string]interface{}{
					"prefix": map[string]interface{}{
						"request": method + " ",
					},
				})
			}

			// Maybe add bytes_sent filter
			if rand.Intn(2) == 0 {
				minBytes := 1000 * rand.Intn(10)
				filters = append(filters, map[string]interface{}{
					"range": map[string]interface{}{
						"bytes_sent": map[string]interface{}{
							"gt": minBytes,
						},
					},
				})
			}

		case "web_error":
			// For web_error logs, add filters based on error levels and codes
			// Add level filter
			levels := []string{"error", "critical"}
			level := levels[rand.Intn(len(levels))]
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"level": level,
				},
			})

			// Maybe add error_code filter
			if rand.Intn(2) == 0 {
				minErrorCode := 1000 + rand.Intn(1000)
				filters = append(filters, map[string]interface{}{
					"range": map[string]interface{}{
						"error_code": map[string]interface{}{
							"gt": minErrorCode,
						},
					},
				})
			}

		case "application":
			// For application logs, add filters based on service name, level, etc.
			// Add service filter
			services := []string{"user-service", "auth-service", "payment-service", "order-service", "catalog-service"}
			service := services[rand.Intn(len(services))]
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"service": service,
				},
			})

			// Add level filter
			levels := []string{"debug", "info", "warn", "error", "critical"}
			level := levels[rand.Intn(len(levels))]
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"level": level,
				},
			})

			// Maybe add response_status filter for service operations
			if rand.Intn(2) == 0 {
				statuses := []int{200, 201, 204, 400, 401, 403, 404, 500}
				status := statuses[rand.Intn(len(statuses))]
				filters = append(filters, map[string]interface{}{
					"term": map[string]interface{}{
						"response_status": status,
					},
				})
			}

		case "metric":
			// For metric logs, filter on metric name and values
			metricNames := []string{"cpu_usage", "memory_usage", "disk_usage", "network_in", "network_out"}
			metricName := metricNames[rand.Intn(len(metricNames))]
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"metric_name": metricName,
				},
			})

			// Maybe add value range filter
			if rand.Intn(2) == 0 {
				minValue := rand.Float64() * 100
				filters = append(filters, map[string]interface{}{
					"range": map[string]interface{}{
						"value": map[string]interface{}{
							"gt": minValue,
						},
					},
				})
			}

		case "event":
			// For event logs, filter on event type
			eventTypes := []string{"system_start", "system_stop", "deploy", "rollback", "config_change"}
			eventType := eventTypes[rand.Intn(len(eventTypes))]
			filters = append(filters, map[string]interface{}{
				"term": map[string]interface{}{
					"event_type": eventType,
				},
			})
		}

		// Maybe add keyword search to message
		if rand.Intn(2) == 0 {
			keyword := esQueryPhrases[rand.Intn(len(esQueryPhrases))]
			filters = append(filters, map[string]interface{}{
				"match": map[string]interface{}{
					"message": keyword,
				},
			})
		}

	case models.AnalyticalQuery:
		// Analytical queries with aggregations based on log type
		logType := esLogTypes[rand.Intn(len(esLogTypes))]

		// Add base log type filter
		filters = append(filters, map[string]interface{}{
			"term": map[string]interface{}{
				"log_type": logType,
			},
		})

		// Add aggregations based on log type
		aggregations := make(map[string]interface{})

		switch logType {
		case "web_access":
			if rand.Intn(2) == 0 {
				// Count by status
				aggregations["status_counts"] = map[string]interface{}{
					"terms": map[string]interface{}{
						"field": "status",
						"size":  20,
					},
				}
			} else {
				// Average bytes sent by status
				aggregations["bytes_by_status"] = map[string]interface{}{
					"terms": map[string]interface{}{
						"field": "status",
						"size":  20,
					},
					"aggs": map[string]interface{}{
						"avg_bytes": map[string]interface{}{
							"avg": map[string]interface{}{
								"field": "bytes_sent",
							},
						},
					},
				}
			}

		case "web_error":
			if rand.Intn(2) == 0 {
				// Count by error_code
				aggregations["error_code_counts"] = map[string]interface{}{
					"terms": map[string]interface{}{
						"field": "error_code",
						"size":  20,
					},
				}
			} else {
				// Count by level
				aggregations["level_counts"] = map[string]interface{}{
					"terms": map[string]interface{}{
						"field": "level",
						"size":  5,
					},
				}
			}

		case "application":
			if rand.Intn(2) == 0 {
				// Count by service
				aggregations["service_counts"] = map[string]interface{}{
					"terms": map[string]interface{}{
						"field": "service",
						"size":  20,
					},
				}
			} else {
				// Count by level
				aggregations["level_counts"] = map[string]interface{}{
					"terms": map[string]interface{}{
						"field": "level",
						"size":  5,
					},
				}
			}

		case "metric":
			// Average value by metric_name
			aggregations["metric_values"] = map[string]interface{}{
				"terms": map[string]interface{}{
					"field": "metric_name",
					"size":  20,
				},
				"aggs": map[string]interface{}{
					"avg_value": map[string]interface{}{
						"avg": map[string]interface{}{
							"field": "value",
						},
					},
				},
			}

		case "event":
			// Count by event_type
			aggregations["event_type_counts"] = map[string]interface{}{
				"terms": map[string]interface{}{
					"field": "event_type",
					"size":  20,
				},
			}

		default:
			// Generic count by log_type
			aggregations["log_type_counts"] = map[string]interface{}{
				"terms": map[string]interface{}{
					"field": "log_type",
					"size":  10,
				},
			}
		}

		// Add aggregations to query
		baseQuery["size"] = 0 // Don't need documents, just aggregations
		baseQuery["aggs"] = aggregations
	case models.TimeSeriesQuery:
		// Date histogram aggregation by minute for one metric
		metricNames := []string{"cpu_usage", "memory_usage", "disk_usage"}
		metricName := metricNames[rand.Intn(len(metricNames))]

		filters = append(filters, map[string]interface{}{
			"term": map[string]interface{}{"metric_name": metricName},
		})

		baseQuery["aggs"] = map[string]interface{}{
			"per_min": map[string]interface{}{
				"date_histogram": map[string]interface{}{
					"field":          "timestamp",
					"fixed_interval": "1m",
				},
				"aggs": map[string]interface{}{
					"avg_value": map[string]interface{}{
						"avg": map[string]interface{}{"field": "value"},
					},
				},
			},
		}

		baseQuery["size"] = 0

	case models.StatQuery:
		// Simple count query
		lt := esLogTypes[rand.Intn(len(esLogTypes))]
		filters = append(filters, map[string]interface{}{
			"term": map[string]interface{}{"log_type": lt},
		})
		baseQuery["size"] = 0

	case models.TopKQuery:
		// Terms aggregation top 10 services
		baseQuery["aggs"] = map[string]interface{}{
			"top_services": map[string]interface{}{
				"terms": map[string]interface{}{
					"field": "service.keyword",
					"size":  10,
				},
			},
		}
		baseQuery["size"] = 0
	}

	// Update the filters in the base query
	baseQuery["query"].(map[string]interface{})["bool"].(map[string]interface{})["filter"] = filters

	// Print debug info about the query if verbose mode is on
	if e.Options.Verbose {
		jsonQuery, _ := json.Marshal(baseQuery)
		fmt.Printf("Debug: Elasticsearch query: %s\n", string(jsonQuery))
	}

	return baseQuery
}

// executeElasticsearchQuery executes a query to Elasticsearch
func (e *ElasticsearchExecutor) executeElasticsearchQuery(ctx context.Context, query map[string]interface{}) (models.QueryResult, error) {
	queryJSON, err := json.Marshal(query)
	if err != nil {
		return models.QueryResult{}, fmt.Errorf("error marshaling query: %v", err)
	}

	// Debug - print the query
	if e.Options.Verbose {
		fmt.Printf("Debug: Elasticsearch query: %s\n", string(queryJSON))
	}

	// Override the query to match all documents if needed
	if e.Options.Verbose && rand.Intn(5) == 0 {
		// Every 5th query, try a match_all query to find any logs in the system
		matchAllQuery := map[string]interface{}{
			"query": map[string]interface{}{
				"match_all": map[string]interface{}{},
			},
			"size": 100,
			"sort": []map[string]interface{}{
				{
					"@timestamp": map[string]interface{}{
						"order": "desc",
					},
				},
			},
		}
		queryJSON, _ = json.Marshal(matchAllQuery)
		fmt.Printf("Debug: Using match_all query: %s\n", string(queryJSON))
	}

	url := fmt.Sprintf("%s/%s/_search", e.BaseURL, e.IndexName)
	req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(queryJSON))
	if err != nil {
		return models.QueryResult{}, fmt.Errorf("error creating request: %v", err)
	}

	req.Header.Set("Content-Type", "application/json")

	startTime := time.Now()
	resp, err := e.Client.Do(req)
	duration := time.Since(startTime)

	if err != nil {
		return models.QueryResult{}, fmt.Errorf("error executing request: %v", err)
	}
	defer resp.Body.Close()

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return models.QueryResult{}, fmt.Errorf("error reading response: %v", err)
	}

	if resp.StatusCode >= 400 {
		var errorResp ESErrorResponse
		if err := json.Unmarshal(body, &errorResp); err != nil {
			return models.QueryResult{}, fmt.Errorf("error parsing error response: %v", err)
		}
		return models.QueryResult{}, fmt.Errorf("elasticsearch error: %s - %s", errorResp.Error.Type, errorResp.Error.Reason)
	}

	var esResp ESSearchResponse
	if err := json.Unmarshal(body, &esResp); err != nil {
		return models.QueryResult{}, fmt.Errorf("error parsing response: %v", err)
	}

	result := models.QueryResult{
		Duration:    duration,
		HitCount:    esResp.Hits.Total.Value,
		ResultCount: esResp.Hits.Total.Value,
		RawResponse: body,
	}

	// If no hits, perform a generic fallback query once
	if result.HitCount == 0 {
		if e.Options.Verbose {
			fmt.Println("Debug: Elasticsearch query returned 0 results, performing match_all fallback")
		}
		fallbackQuery := map[string]interface{}{
			"query": map[string]interface{}{
				"match_all": map[string]interface{}{},
			},
			"size": 100,
		}
		// Avoid infinite recursion by checking special field
		if _, tried := query["_fallback"]; !tried {
			fallbackQuery["_fallback"] = true
			return e.executeElasticsearchQuery(ctx, fallbackQuery)
		}
	}

	return result, nil
}
